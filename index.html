<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Shangqi Gao (高尚奇) </title> <meta name="author" content="Shangqi Gao"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://shangqigao.github.io/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">People </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Shangqi Gao (高尚奇) </h1> <p class="desc">Researcher, <a href="#">Early Cancer Institute</a> CB2 0XZ, University of Cambridge, UK</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/gsqProfile-480.webp 480w,/assets/img/gsqProfile-800.webp 800w,/assets/img/gsqProfile-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/gsqProfile.jpg?3e429c251154d58d52030d8ee57de2ea" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="gsqProfile.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p>shqgao at 163 dot com</p> <p>shangqigao at google dot com</p> </div> </div> <div class="clearfix"> <p>I am a Research Associate at University of Cambridge, and working with <a href="https://www.oncology.cam.ac.uk/research/our-research/crispin" rel="external nofollow noopener" target="_blank">Dr Mireia Crispin</a> and <a href="https://crukcambridgecentre.org.uk/users/jdb1003" rel="external nofollow noopener" target="_blank">Prof James Brenton</a>. Before that, I was a Postdoctoral Research Assistant at University of Oxford, and working with <a href="https://www.nds.ox.ac.uk/team/clare-verrill" rel="external nofollow noopener" target="_blank">Prof. Clare Verrill</a> and <a href="https://www.ndm.ox.ac.uk/team/jens-rittscher" rel="external nofollow noopener" target="_blank">Prof. Jens Rittscher</a>. I got my PhD in statistics from Fudan University under the supervision of <a href="https://zmiclab.github.io/zxh/" rel="external nofollow noopener" target="_blank">Prof. Xiahai Zhuang</a>, MSc in applied mathematics from Wuhan University under the superevision of Prof. Qibin Fan, and BSc in mathematics and applied mathematics from Northwestern Polytechnical University under the supervision of Prof. Pengcheng Niu. I got the <a href="https://miccai.org/index.php/about-miccai/awards/medical-image-analysis-best-paper-award/#:~:text=The%20MICCAI%20MedIA%20Best%20Paper,the%20award%20between%20two%20winners." rel="external nofollow noopener" target="_blank">Elsevier-MedIA 1st Prize &amp; Medical Image Analysis MICCAI Best Paper Award</a> in 2023. I am serving as the president of <a href="https://miccai.org/index.php/special-interest-groups/sig-xmedia/" rel="external nofollow noopener" target="_blank">MICCAI SIG-xMedIA</a>.</p> <p>I focus on inverse problems, computational imaging, Bayesian deep learning, and multi-omic data analysis. Particularly, I am interested in explainable and generalizable AI for computer vision, medical image analysis, and cancer research.</p> <p>My PhD thesis is “Deep Image Decomposition and Reconstruction”. This dissertation chronicles deep learning-based mathematical and statistical frameworks for solving inverse problems in photography and medical imaging as well as their applications in natural image super-resolution and medical image segmentation.</p> <p>My MSc thesis is “Regularization-Based Approaches for Tensor Completion”. This dissertation chronicles regularization approaches for solving inverse problems in tensor completion as well as their applications in color images, color videos, and magnetic resonance images.</p> <p>I contribute to the peer review for <em>Cancer Discovery</em> (<strong>IF: 30.6</strong>), <em>Nature Communications</em> (<strong>IF: 14.7</strong>), <em>Medical Image Analysis</em> (<strong>IF: 10.7</strong>), <em>IEEE TMI</em> (<strong>IF: 10.6</strong>), <em>IEEE TNNLS</em> (<strong>IF: 10.2</strong>), Neural Networks, CVPR, ICCV, ECCV, and MICCAI.</p> </div> <h2> <a href="/news/" style="color: inherit">Latest news 🔥🔥🔥</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Jun 17, 2025</th> <td> <a class="news-title" href="/news/announcement_11/">Four of our papers have been accepted by MICCAi2025</a> </td> </tr> <tr> <th scope="row" style="width: 20%">May 27, 2025</th> <td> <a class="news-title" href="/news/announcement_9/">Our MICCAI SIG-xMedIA Online Seminar is taking place!</a> </td> </tr> <tr> <th scope="row" style="width: 20%">May 25, 2025</th> <td> <strong>Join us—The MICCAI 2025 CARE Challenge is live!</strong> <hr> 🌈🌈🌈 Welcome to participate our <a href="https://zmic.org.cn/care_2025/" rel="external nofollow noopener" target="_blank">MICCAI 2025 CARE challenge</a>: Toward Real-World Medical Image Analysis. We provide <strong>1300+ cases from 18 centers</strong>. </td> </tr> <tr> <th scope="row" style="width: 20%">May 03, 2025</th> <td> <a class="news-title" href="/news/announcement_4/">Join SIG-xMedIA for Advancing Explainable AI in Medical Imaging</a> </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 12, 2024</th> <td> <a class="news-title" href="/news/announcement_1/">Guest lecture on Image Processing and Analysis</a> </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">Selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/bayeseg_demo.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="bayeseg_demo.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="GAO2023102889" class="col-sm-8"> <div class="title">BayeSeg: Bayesian modeling for medical image segmentation with interpretable generalizability</div> <div class="author"> <em>Shangqi Gao</em>, <a href="https://ieeexplore.ieee.org/author/37088955032" rel="external nofollow noopener" target="_blank">Hangqi Zhou</a>, <a href="https://obiyoag.github.io" rel="external nofollow noopener" target="_blank">Yibo Gao</a>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Xiahai Zhuang' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Medical Image Analysis</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Awarded</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.media.2023.102889" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/obiyoag/BayeSeg" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://www.bilibili.com/video/BV1it421p7qE/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1016/j.media.2023.102889" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=D-jg5rUAAAAJ&amp;citation_for_view=D-jg5rUAAAAJ:roLk4NBRz8UC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Elsevier-MedIA 1st Prize &amp; Medical Image Analysis MICCAI Best Paper Award 2023</p> </div> <div class="abstract hidden"> <p>Due to the cross-domain distribution shift aroused from diverse medical imaging systems, many deep learning segmentation methods fail to perform well on unseen data, which limits their real-world applicability. Recent works have shown the benefits of extracting domain-invariant representations on domain generalization. However, the interpretability of domain-invariant features remains a great challenge. To address this problem, we propose an interpretable Bayesian framework (BayeSeg) through Bayesian modeling of image and label statistics to enhance model generalizability for medical image segmentation. Specifically, we first decompose an image into a spatial-correlated variable and a spatial-variant variable, assigning hierarchical Bayesian priors to explicitly force them to model the domain-stable shape and domain-specific appearance information respectively. Then, we model the segmentation as a locally smooth variable only related to the shape. Finally, we develop a variational Bayesian framework to infer the posterior distributions of these explainable variables. The framework is implemented with neural networks, and thus is referred to as deep Bayesian segmentation. Quantitative and qualitative experimental results on prostate segmentation and cardiac segmentation tasks have shown the effectiveness of our proposed method. Moreover, we investigated the interpretability of BayeSeg by explaining the posteriors and analyzed certain factors that affect the generalization ability through further ablation studies. Our code is released via https://zmiclab.github.io/projects.html.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">GAO2023102889</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{BayeSeg: Bayesian modeling for medical image segmentation with interpretable generalizability}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Medical Image Analysis}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{89}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{102889}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1361-8415}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.media.2023.102889}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S1361841523001494}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gao, Shangqi and Zhou, Hangqi and Gao, Yibo and Zhuang, Xiahai}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Image segmentation, Interpretation and generalization, Statistical modeling, Variational Bayes}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/bayesr_demo.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="bayesr_demo.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Gao9744488" class="col-sm-8"> <div class="title">Bayesian Image Super-Resolution With Deep Modeling of Image Statistics</div> <div class="author"> <em>Shangqi Gao</em> and <a href="https://zmiclab.github.io/zxh/" rel="external nofollow noopener" target="_blank">Xiahai Zhuang</a> </div> <div class="periodical"> <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TPAMI.2022.3163307" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/shangqigao/BayeSR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/TPAMI.2022.3163307" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=D-jg5rUAAAAJ&amp;citation_for_view=D-jg5rUAAAAJ:zYLM7Y9cAGgC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Modeling statistics of image priors is useful for image super-resolution, but little attention has been paid from the massive works of deep learning-based methods. In this work, we propose a Bayesian image restoration framework, where natural image statistics are modeled with the combination of smooth- ness and sparsity priors. Concretely, firstly we consider an ideal image as the sum of a smoothness component and a sparsity residual, and model real image degradation including blurring, downscaling, and noise corruption. Then, we develop a variational Bayesian approach to infer their posteriors. Finally, we implement the variational approach for single image super-resolution (SISR) using deep neural networks, and propose an unsupervised training strategy. The experiments on three image restoration tasks, i.e., ideal SISR, realistic SISR, and real-world SISR, demonstrate that our method has superior model generalizability against varying noise levels and degradation kernels and is effective in unsupervised SISR. The code and resulting models are released via https://zmiclab.github.io/projects.html.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Gao9744488</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gao, Shangqi and Zhuang, Xiahai}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Pattern Analysis and Machine Intelligence}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Bayesian Image Super-Resolution With Deep Modeling of Image Statistics}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{45}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1405-1423}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Image restoration;Bayes methods;Computational modeling;Mathematical models;Superresolution;Task analysis;Image denoising;Image super-resolution;variational inference;neural network;generative learning}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TPAMI.2022.3163307}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/ronet_demo.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ronet_demo.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Gao9303377" class="col-sm-8"> <div class="title">Rank-One Network: An Effective Framework for Image Restoration</div> <div class="author"> <em>Shangqi Gao</em> and <a href="https://zmiclab.github.io/zxh/" rel="external nofollow noopener" target="_blank">Xiahai Zhuang</a> </div> <div class="periodical"> <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TPAMI.2020.3046476" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/shangqigao/RONet" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/TPAMI.2020.3046476" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=D-jg5rUAAAAJ&amp;citation_for_view=D-jg5rUAAAAJ:qjMakFHDy7sC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>The principal rank-one (RO) components of an image represent the self- similarity of the image, which is an important property for image restoration. However, the RO components of a corrupted image could be decimated by the procedure of image denoising. We suggest that the RO property should be utilized and the decimation should be avoided in image restoration. To achieve this, we propose a new framework comprised of two modules, i.e., the RO decomposition and RO reconstruction. The RO decomposition is devel- oped to decompose a corrupted image into the RO components and residual. This is achieved by successively applying RO projections to the image or its residuals to extract the RO components. The RO projections, based on neural networks, extract the closest RO component of an image. The RO reconstruction is aimed to reconstruct the important information, respec- tively from the RO components and residual, as well as to restore the image from this reconstructed information. Experimental results on four tasks, i.e., noise-free image super-resolution (SR), realistic image SR, gray-scale image denoising, and color image denoising, show that the method is effective and efficient for image restoration, and it delivers superior performance for real- istic image SR and color image denoising.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Gao9303377</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gao, Shangqi and Zhuang, Xiahai}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Pattern Analysis and Machine Intelligence}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Rank-One Network: An Effective Framework for Image Restoration}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{44}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3224-3238}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Image restoration;Image reconstruction;Image denoising;Neural networks;Task analysis;Matrix decomposition;Noise reduction;Image restoration;rank one;super resolution;neural network}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TPAMI.2020.3046476}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/SpBCD_JSC2020.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="SpBCD_JSC2020.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Gao2020robust" class="col-sm-8"> <div class="title">Robust Schatten-p norm based approach for tensor completion</div> <div class="author"> <em>Shangqi Gao</em> and Qibin Fan </div> <div class="periodical"> <em>Journal of Scientific Computing</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/s10915-019-01108-9" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/shangqigao/TensorCompletion" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/s10915-019-01108-9" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=D-jg5rUAAAAJ&amp;citation_for_view=D-jg5rUAAAAJ:u-x6o8ySG0sC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>The matrix nuclear norm has been widely applied to approximate the matrix rank for low-rank tensor completion because of its convexity. However, this relaxation may make the solution seriously deviate from the original solution for real-world data recovery. In this paper, using a nonconvex approximation of rank, i.e., the Schatten-p norm, we propose a novel model for tensor completion. It’s hard to solve this model directly because the objective function of the model is nonconvex. To solve the model, we develop a variant of this model via the classical quadric penalty method, and propose an algorithm, i.e., SpBCD, based on the block coordinate descent method. Although the objective function of the variant is nonconvex, we show that the sequence generated by SpBCD is convergent to a critical point. Our numerical experiments on real-world data show that SpBCD delivers state-of-art performance in recovering missing data.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Gao2020robust</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Robust Schatten-p norm based approach for tensor completion}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gao, Shangqi and Fan, Qibin}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Scientific Computing}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{82}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--23}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/s10915-019-01108-9}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s10915-019-01108-9}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/S-LRTC_JSC2018.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="S-LRTC_JSC2018.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Gao2018JSC" class="col-sm-8"> <div class="title">A Mixture of Nuclear Norm and Matrix Factorization for Tensor Completion</div> <div class="author"> <em>Shangqi Gao</em> and Qibin Fan </div> <div class="periodical"> <em>J. Sci. Comput.</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/s10915-017-0521-9" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/shangqigao/TensorCompletion" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/s10915-017-0521-9" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=D-jg5rUAAAAJ&amp;citation_for_view=D-jg5rUAAAAJ:u5HHmVD_uO8C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>In this paper, we propose a mixture model for tensor completion by combining the nuclear norm with the low-rank matrix factorization. To solve this model, we develop two algorithms: non-smooth low-rank tensor completion (NS-LRTC), smooth low-rank tensor completion (S-LRTC). When the sampling rate (SR) is high, our experiments on real-world data show that the NS-LRTC algorithm outperforms other tested methods in running time and recovery quality. In addition, whatever the SR is, the proposed S-LRTC algorithm delivers state-of-art recovery performance compared with other tested approaches. Although the objective function in our model is non-convex and non-differentiable, we prove that every cluster point of the sequence generated by NS-LRTC or S-LRTC is a stationary point.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Gao2018JSC</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gao, Shangqi and Fan, Qibin}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Mixture of Nuclear Norm and Matrix Factorization for Tensor Completion}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">issue_date</span> <span class="p">=</span> <span class="s">{April 2018}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Plenum Press}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{USA}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{75}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0885-7474}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/s10915-017-0521-9}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s10915-017-0521-9}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{J. Sci. Comput.}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{43–64}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{22}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Tensor completion, Nuclear norm, Matrix factorization, Block coordinate descent}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="https://github.com/shangqigao" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/shangqi-gao-a93459290" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://orcid.org/0000-0003-4567-1636" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fa-solid fa-square-rss"></i></a> <a href="https://scholar.google.com/citations?user=D-jg5rUAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> </div> <div class="contact-note">You can quickly reach me by LinkedIn. </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Shangqi Gao. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>